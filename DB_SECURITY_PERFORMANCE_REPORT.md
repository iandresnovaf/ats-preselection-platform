# Informe de Revisi√≥n: Base de Datos - Seguridad y Performance
## ATS Platform - Fecha: 2026-02-17

---

## üîí HALLAZGOS DE SEGURIDAD

### 1. Configuraci√≥n de Usuarios y Permisos

#### ‚ùå CR√çTICO: Uso de usuario root/ postgres en runtime
**Archivo:** `backend/app/core/database.py` y `docker-compose.yml`

**Problema:**
```python
# docker-compose.yml
postgres:
  environment:
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
```

```python
# database.py
DATABASE_URL = settings.DATABASE_URL  # Sin configuraci√≥n de usuario por servicio
```

**Riesgo:** El backend se conecta con el usuario postgres (superusuario) en lugar de usar usuarios con permisos m√≠nimos por servicio.

**Recomendaci√≥n:**
```sql
-- Crear usuarios espec√≠ficos por servicio
CREATE USER ats_backend WITH PASSWORD 'secure_random_password';
CREATE USER ats_worker WITH PASSWORD 'secure_random_password';

-- Permisos m√≠nimos para backend (solo lectura/escritura en tablas de aplicaci√≥n)
GRANT CONNECT ON DATABASE ats_platform TO ats_backend;
GRANT USAGE ON SCHEMA public TO ats_backend;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO ats_backend;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO ats_backend;

-- Permisos para worker (m√°s restrictivos si es necesario)
GRANT CONNECT ON DATABASE ats_platform TO ats_worker;
GRANT USAGE ON SCHEMA public TO ats_worker;
GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO ats_worker;
```

---

### 2. Cifrado en Tr√°nsito (SSL/TLS)

#### ‚ùå CR√çTICO: No hay configuraci√≥n de SSL/TLS para conexiones a BD

**Archivo:** `backend/app/core/database.py`

**Problema:**
```python
engine = create_async_engine(
    DATABASE_URL,
    pool_size=10,
    max_overflow=20,
    # ... Falta sslmode=require
)
```

**Riesgo:** Las conexiones a la base de datos viajan sin cifrado en la red interna.

**Recomendaci√≥n:**
```python
# Para conexiones con SSL
engine = create_async_engine(
    DATABASE_URL,
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,
    echo=settings.DEBUG,
    future=True,
    connect_args={
        "ssl": "require"  # Requiere SSL para todas las conexiones
    } if not settings.DEBUG else {}
)
```

**Para Docker Compose (producci√≥n):**
```yaml
# A√±adir a docker-compose.yml para postgres
postgres:
  command:
    - "postgres"
    - "-c"
    - "ssl=on"
    - "-c"
    - "ssl_cert_file=/etc/ssl/certs/server.crt"
    - "-c"
    - "ssl_key_file=/etc/ssl/private/server.key"
  volumes:
    - ./ssl/server.crt:/etc/ssl/certs/server.crt:ro
    - ./ssl/server.key:/etc/ssl/private/server.key:ro
```

---

### 3. Cifrado en Reposos

#### ‚ö†Ô∏è MEDIO: No hay configuraci√≥n expl√≠cita de cifrado en reposo

**Estado actual:** No se ha encontrado configuraci√≥n de:
- TDE (Transparent Data Encryption) de PostgreSQL
- Cifrado a nivel de columna para datos sensibles
- Encriptaci√≥n de backups

**Recomendaci√≥n:**

Para PostgreSQL en producci√≥n, considerar:
1. **PostgreSQL TDE** (requiere pg_crypto o pgcrypto extension):
```sql
-- Habilitar extensi√≥n de cifrado
CREATE EXTENSION IF NOT EXISTS pgcrypto;

-- Ejemplo: Cifrar datos sensibles de candidatos
ALTER TABLE hh_candidates ADD COLUMN email_encrypted BYTEA;

-- Funci√≥n para insertar datos cifrados
UPDATE hh_candidates 
SET email_encrypted = pgp_sym_encrypt(email, current_setting('app.encryption_key'));
```

2. **Cifrado a nivel de sistema de archivos:**
```bash
# Para vol√∫menes Docker en producci√≥n
# Usar LUKS o similar para cifrar el volumen de postgres_data
docker volume create --driver local \
  --opt type=none \
  --opt o=bind \
  --opt device=/encrypted/path/postgres_data \
  postgres_data_encrypted
```

**Datos que deber√≠an cifrarse:**
- `hh_candidates.email`, `hh_candidates.phone`, `hh_candidates.national_id`
- `hh_documents.storage_uri` (si contiene tokens)
- `hh_cv_processing.raw_text` (contiene datos personales)
- `hh_cv_extractions.raw_text`

---

### 4. Pol√≠tica de Backups

#### ‚ùå CR√çTICO: No hay pol√≠tica de backups automatizados visible

**Estado actual:** No se encontr√≥:
- Scripts de backup automatizado
- Configuraci√≥n de backup en docker-compose
- Pol√≠tica de retenci√≥n
- Pruebas de restore

**Recomendaci√≥n - Implementar soluci√≥n de backup:**

```yaml
# A√±adir a docker-compose.yml
pg_backup:
  image: postgres:15-alpine
  container_name: ats_pg_backup
  environment:
    - POSTGRES_USER=postgres
    - POSTGRES_PASSWORD=postgres
    - BACKUP_DIR=/backups
    - RETENTION_DAYS=30
  volumes:
    - ./backups:/backups
    - ./scripts/backup.sh:/backup.sh:ro
  command: >
    sh -c "echo '0 2 * * * /backup.sh' | crontab - && crond -f"
  depends_on:
    - postgres
  networks:
    - ats-network
```

```bash
#!/bin/bash
# scripts/backup.sh
set -e

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/ats_backup_${TIMESTAMP}.sql.gz"

echo "Iniciando backup: ${BACKUP_FILE}"

# Backup completo con pg_dump
PGPASSWORD=${POSTGRES_PASSWORD} pg_dump \
  -h postgres \
  -U ${POSTGRES_USER} \
  -d ats_platform \
  --verbose \
  --no-owner \
  --no-privileges \
  | gzip > ${BACKUP_FILE}

# Verificar integridad
if [ $? -eq 0 ]; then
    echo "Backup completado exitosamente: ${BACKUP_FILE}"
    
    # Calcular hash para verificaci√≥n
    sha256sum ${BACKUP_FILE} > ${BACKUP_FILE}.sha256
    
    # Eliminar backups antiguos
    find ${BACKUP_DIR} -name "ats_backup_*.sql.gz" -mtime +${RETENTION_DAYS} -delete
    find ${BACKUP_DIR} -name "ats_backup_*.sql.gz.sha256" -mtime +${RETENTION_DAYS} -delete
else
    echo "ERROR: El backup fall√≥"
    exit 1
fi
```

**Pruebas de Restore (mensuales):**
```bash
#!/bin/bash
# scripts/test_restore.sh - Ejecutar mensualmente

RESTORE_DB="ats_platform_restore_test"
LATEST_BACKUP=$(ls -t ${BACKUP_DIR}/ats_backup_*.sql.gz | head -1)

echo "Probando restore desde: ${LATEST_BACKUP}"

# Crear BD temporal
PGPASSWORD=${POSTGRES_PASSWORD} psql -h postgres -U ${POSTGRES_USER} -c "CREATE DATABASE ${RESTORE_DB};"

# Restaurar backup
gunzip < ${LATEST_BACKUP} | PGPASSWORD=${POSTGRES_PASSWORD} psql -h postgres -U ${POSTGRES_USER} -d ${RESTORE_DB}

# Verificar integridad
TABLE_COUNT=$(PGPASSWORD=${POSTGRES_PASSWORD} psql -h postgres -U ${POSTGRES_USER} -d ${RESTORE_DB} -t -c "SELECT count(*) FROM information_schema.tables WHERE table_schema='public';")

echo "Tablas restauradas: ${TABLE_COUNT}"

# Limpiar
PGPASSWORD=${POSTGRES_PASSWORD} psql -h postgres -U ${POSTGRES_USER} -c "DROP DATABASE ${RESTORE_DB};"

echo "Prueba de restore completada exitosamente"
```

---

### 5. Auditor√≠a de Cambios

#### ‚úÖ BUENO: Auditor√≠a b√°sica implementada

**Archivo:** `backend/app/models/core_ats.py` - `HHAuditLog`

```python
class HHAuditLog(Base):
    """Registro de auditor√≠a para trazabilidad total."""
    __tablename__ = "hh_audit_log"
    
    __table_args__ = (
        Index('idx_hh_audit_entity', 'entity_type', 'entity_id'),
        Index('idx_hh_audit_changed_at', 'changed_at'),
    )
    
    audit_id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    entity_type = Column(Text, nullable=False)
    entity_id = Column(UUID(as_uuid=True), nullable=False)
    action = Column(SQLEnum(AuditAction), nullable=False)
    changed_by = Column(Text, nullable=True)
    changed_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    diff_json = Column(JSONB, nullable=True)
```

**Hallazgo:** La auditor√≠a est√° implementada pero podr√≠a mejorarse:

```sql
-- Mejoras recomendadas para auditor√≠a
-- 1. Tabla de auditor√≠a m√°s completa
CREATE TABLE audit_logs_detailed (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    table_name TEXT NOT NULL,
    record_id UUID NOT NULL,
    action TEXT NOT NULL CHECK (action IN ('INSERT', 'UPDATE', 'DELETE')),
    old_data JSONB,
    new_data JSONB,
    changed_by TEXT,
    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ip_address INET,
    user_agent TEXT,
    session_id TEXT
);

-- √çndices para consultas frecuentes
CREATE INDEX idx_audit_table_record ON audit_logs_detailed(table_name, record_id);
CREATE INDEX idx_audit_changed_at ON audit_logs_detailed(changed_at DESC);
CREATE INDEX idx_audit_action ON audit_logs_detailed(action);

-- 2. Trigger autom√°tico para todas las tablas sensibles
CREATE OR REPLACE FUNCTION audit_trigger_func()
RETURNS TRIGGER AS $$
BEGIN
    IF (TG_OP = 'DELETE') THEN
        INSERT INTO audit_logs_detailed (table_name, record_id, action, old_data)
        VALUES (TG_TABLE_NAME, OLD.candidate_id, 'DELETE', to_jsonb(OLD));
    ELSIF (TG_OP = 'UPDATE') THEN
        INSERT INTO audit_logs_detailed (table_name, record_id, action, old_data, new_data)
        VALUES (TG_TABLE_NAME, NEW.candidate_id, 'UPDATE', to_jsonb(OLD), to_jsonb(NEW));
    ELSIF (TG_OP = 'INSERT') THEN
        INSERT INTO audit_logs_detailed (table_name, record_id, action, new_data)
        VALUES (TG_TABLE_NAME, NEW.candidate_id, 'INSERT', to_jsonb(NEW));
    END IF;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
```

---

## ‚ö° HALLAZGOS DE PERFORMANCE

### 1. √çndices Definidos

#### ‚úÖ EXCELENTE: √çndices bien definidos para queries frecuentes

**Archivo:** `backend/app/models/core_ats.py` y migraciones

**√çndices principales implementados:**

```python
# HHCandidate - B√∫squedas por email, documento, nombre
__table_args__ = (
    Index('idx_hh_candidates_email', 'email'),
    Index('idx_hh_candidates_national_id', 'national_id'),
    Index('idx_hh_candidates_name', 'full_name'),
    Index('idx_hh_candidates_created', 'created_at'),
)

# HHApplication - ENTIDAD CENTRAL con √≠ndices cr√≠ticos
__table_args__ = (
    Index('idx_hh_applications_candidate', 'candidate_id'),
    Index('idx_hh_applications_role', 'role_id'),
    Index('idx_hh_applications_stage', 'stage'),
    Index('idx_hh_applications_hired', 'hired'),
    Index('idx_hh_applications_score', 'overall_score'),
    UniqueConstraint('candidate_id', 'role_id', name='uix_hh_applications_candidate_role'),
)

# HHRole - B√∫squedas por cliente y estado
__table_args__ = (
    Index('idx_hh_roles_client', 'client_id'),
    Index('idx_hh_roles_status', 'status'),
    Index('idx_hh_roles_title', 'role_title'),
)
```

**√çndices de migraci√≥n 20260216_001_core_ats_data_model.py:**
- ‚úÖ `idx_candidates_email` - B√∫squedas frecuentes por email
- ‚úÖ `idx_candidates_national_id` - B√∫squedas por documento
- ‚úÖ `idx_applications_role_stage` - Filtrado por vacante y etapa
- ‚úÖ `idx_applications_candidate_hired` - Consultas de candidatos contratados
- ‚úÖ `idx_applications_overall_score` - Ranking por score
- ‚úÖ `idx_flags_app_severity` - Alertas por severidad
- ‚úÖ `idx_audit_logs_entity` - Auditor√≠a por entidad

---

### 2. Optimizaci√≥n de Consultas - N+1 Queries

#### ‚ö†Ô∏è MEDIO: Algunos casos de potenciales N+1 queries detectados

**Archivo:** `backend/app/api/v1/roles.py` - Funci√≥n `list_roles()`

**Problema detectado:**
```python
# L√≠neas ~68-82
result = await db.execute(query)
roles = result.unique().scalars().all()

# Get all client IDs and fetch clients in one query
client_ids = [r.client_id for r in roles]
clients_result = await db.execute(
    select(HHClient).where(HHClient.client_id.in_(client_ids))
)
clients = {c.client_id: c for c in clients_result.scalars().all()}
```

**An√°lisis:** Este es un patr√≥n N+1 manual - aunque hace 2 queries en lugar de N+1, es menos eficiente que usar `joinedload` o `selectinload`.

**Optimizaci√≥n recomendada:**
```python
# Usar selectinload para cargar relaciones eficientemente
query = select(HHRole).options(selectinload(HHRole.client))

# Ahora solo se hace 1 query con JOIN impl√≠cito
result = await db.execute(query)
roles = result.unique().scalars().all()

# No necesita query adicional para clientes
for role in roles:
    client_name = role.client.client_name  # Ya cargado
```

---

**Archivo:** `backend/app/api/v1/applications.py` - Uso correcto de eager loading ‚úÖ**

```python
# L√≠neas ~98-103 - BUEN USO de joinedload
query = select(HHApplication).options(
    joinedload(HHApplication.candidate),
    joinedload(HHApplication.role).joinedload(HHRole.client)
)
```

**An√°lisis:** Uso correcto de `joinedload` para relaciones many-to-one. Esto evita N+1 queries.

---

**Archivo:** `backend/app/services/matching_service.py` - Posible optimizaci√≥n**

**Problema:**
```python
# L√≠neas ~208-218
if candidate.documents:
    for doc in candidate.documents:  # Puede ser N queries
        extraction_result = await self.db.execute(
            select(DocumentTextExtraction)
            .where(DocumentTextExtraction.document_id == doc.id)
        )
```

**Optimizaci√≥n:**
```python
# Usar selectinload en la carga inicial del candidato
from sqlalchemy.orm import selectinload

result = await self.db.execute(
    select(Candidate)
    .where(Candidate.id == candidate_id)
    .options(
        selectinload(Candidate.documents).
        selectinload(Document.extractions)  # Cargar todo en 2 queries
    )
)
```

---

### 3. Paginaci√≥n Implementada

#### ‚úÖ BUENO: Paginaci√≥n implementada correctamente

**Offset-based pagination (usada en listados):**
```python
# backend/app/services/job_service.py
async def list_jobs(..., skip: int = 0, limit: int = 100):
    # Contar total
    count_query = select(func.count()).select_from(query.subquery())
    total_result = await self.db.execute(count_query)
    total = total_result.scalar()
    
    # Ordenar y paginar
    query = query.order_by(desc(JobOpening.created_at))
    query = query.offset(skip).limit(limit)
```

**Cursor-based pagination (m√°s eficiente para grandes datasets):**
```python
# backend/app/services/job_service.py - list_jobs_cursor()
async def list_jobs_cursor(
    self,
    cursor: Optional[str] = None,
    limit: int = 20,
    ...
) -> Tuple[List[JobOpening], Optional[str]]:
    # Query base ordenada por created_at
    query = select(JobOpening).order_by(JobOpening.created_at.desc())
    
    # Aplicar cursor (paginaci√≥n)
    if cursor:
        cursor_date = decode_cursor(cursor)
        query = query.where(JobOpening.created_at < cursor_date)
    
    # Pedir limit + 1 para saber si hay m√°s p√°ginas
    query = query.limit(limit + 1)
```

**Recomendaci√≥n:** Para tablas grandes (>100k registros), usar cursor-based pagination exclusivamente para mejor performance.

---

### 4. Pool de Conexiones

#### ‚úÖ BUENO: Configuraci√≥n adecuada del pool

**Archivo:** `backend/app/core/database.py`

```python
engine = create_async_engine(
    DATABASE_URL,
    pool_size=10,              # Conexiones mantenidas permanentemente
    max_overflow=20,           # Conexiones adicionales bajo carga
    pool_timeout=30,           # Segundos esperando conexi√≥n disponible
    pool_recycle=1800,         # Reciclar conexiones cada 30 minutos
    echo=settings.DEBUG,
    future=True,
)
```

**An√°lisis:**
- ‚úÖ `pool_size=10`: Bueno para carga moderada
- ‚úÖ `max_overflow=20`: Permite hasta 30 conexiones totales bajo pico
- ‚úÖ `pool_timeout=30`: Evita esperas indefinidas
- ‚úÖ `pool_recycle=1800`: Evita problemas de conexiones stale (30 min)

**Recomendaci√≥n para producci√≥n con alta carga:**
```python
# Para 100+ usuarios concurrentes
engine = create_async_engine(
    DATABASE_URL,
    pool_size=20,              # Aumentar base
    max_overflow=30,           # M√°s overflow para picos
    pool_timeout=30,
    pool_recycle=1800,
    pool_pre_ping=True,        # Verificar conexi√≥n antes de usarla
    echo=settings.DEBUG,
    future=True,
)
```

---

### 5. Migraciones Reversibles

#### ‚úÖ BUENO: Migraciones con downgrade implementado

**Archivo:** `backend/migrations/versions/20260216_001_core_ats_data_model.py`

**Upgrade (creaci√≥n):**
```python
def upgrade():
    # Crear ENUMs
    rolestatus = postgresql.ENUM('open', 'hold', 'closed', name='rolestatus')
    rolestatus.create(op.get_bind())
    
    # Crear tablas
    op.create_table('candidates', ...)
    op.create_table('clients', ...)
    ...
```

**Downgrade (reversi√≥n) - Completo:**
```python
def downgrade():
    # Eliminar vistas
    op.execute("DROP VIEW IF EXISTS v_candidates_summary")
    op.execute("DROP VIEW IF EXISTS v_roles_summary")
    op.execute("DROP VIEW IF EXISTS v_applications_summary")
    
    # Eliminar triggers
    for table in tables_with_updated_at:
        op.execute(f"DROP TRIGGER IF EXISTS trg_{table}_updated_at ON {table}")
    
    op.execute("DROP FUNCTION IF EXISTS update_updated_at_column()")
    
    # Eliminar tablas en orden inverso (respetando FKs)
    op.drop_table('audit_logs')
    op.drop_table('flags')
    ...
    
    # Eliminar ENUMs
    op.execute("DROP TYPE IF EXISTS auditaction")
    ...
```

**Validaci√≥n:**
```bash
# Comando para verificar que las migraciones son reversibles
cd /ats-platform/backend
alembic downgrade -1  # Probar revertir una migraci√≥n
alembic upgrade head  # Volver al estado actual
```

---

## üìä QUERIES DE OPTIMIZACI√ìN RECOMENDADAS

### Query 1: B√∫squeda de candidatos con filtros complejos

**Escenario:** Dashboard con b√∫squeda de candidatos por nombre, email, ubicaci√≥n, y a√±os de experiencia.

**Query actual (problemas potenciales):**
```python
# Posible problema de performance con ILIKE
query = select(HHCandidate).where(
    or_(
        HHCandidate.full_name.ilike(f"%{search}%"),
        HHCandidate.email.ilike(f"%{search}%"),
    )
)
```

**Optimizaci√≥n - Usar Full Text Search de PostgreSQL:**
```sql
-- Agregar columna de b√∫squeda con tsvector
ALTER TABLE hh_candidates ADD COLUMN search_vector tsvector;

-- Crear √≠ndice GIN para b√∫squeda full-text
CREATE INDEX idx_hh_candidates_search ON hh_candidates USING GIN(search_vector);

-- Funci√≥n para actualizar el vector de b√∫squeda
CREATE OR REPLACE FUNCTION update_candidate_search_vector()
RETURNS TRIGGER AS $$
BEGIN
    NEW.search_vector := 
        setweight(to_tsvector('spanish', COALESCE(NEW.full_name, '')), 'A') ||
        setweight(to_tsvector('spanish', COALESCE(NEW.email, '')), 'B') ||
        setweight(to_tsvector('spanish', COALESCE(NEW.location, '')), 'C');
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger para mantener actualizado el vector
CREATE TRIGGER trg_update_search_vector
    BEFORE INSERT OR UPDATE ON hh_candidates
    FOR EACH ROW
    EXECUTE FUNCTION update_candidate_search_vector();
```

**Query optimizada:**
```python
from sqlalchemy import func, text

# B√∫squeda con full-text
search_query = func.plainto_tsquery('spanish', search_term)
query = select(HHCandidate).where(
    HHCandidate.search_vector.op('@@')(search_query)
).order_by(
    func.ts_rank(HHCandidate.search_vector, search_query).desc()
)
```

---

### Query 2: Reporte de pipeline con m√©tricas agregadas

**Escenario:** Dashboard de consultor mostrando m√©tricas del pipeline.

**Query optimizada con CTE (Common Table Expression):**
```sql
-- Vista materializada para m√©tricas del pipeline
CREATE MATERIALIZED VIEW mv_pipeline_metrics AS
WITH application_stats AS (
    SELECT 
        role_id,
        stage,
        COUNT(*) as count,
        AVG(overall_score) as avg_score,
        MAX(created_at) as last_activity
    FROM hh_applications
    GROUP BY role_id, stage
),
flag_stats AS (
    SELECT 
        a.role_id,
        COUNT(*) FILTER (WHERE f.severity = 'high') as high_flags,
        COUNT(*) FILTER (WHERE f.severity = 'medium') as medium_flags
    FROM hh_applications a
    LEFT JOIN hh_flags f ON a.application_id = f.application_id
    GROUP BY a.role_id
)
SELECT 
    r.role_id,
    r.role_title,
    c.client_name,
    COALESCE(jsonb_object_agg(ast.stage, ast.count) FILTER (WHERE ast.stage IS NOT NULL), '{}'::jsonb) as stage_counts,
    COALESCE(fs.high_flags, 0) as high_flags,
    COALESCE(fs.medium_flags, 0) as medium_flags,
    MAX(ast.last_activity) as last_activity
FROM hh_roles r
JOIN hh_clients c ON r.client_id = c.client_id
LEFT JOIN application_stats ast ON r.role_id = ast.role_id
LEFT JOIN flag_stats fs ON r.role_id = fs.role_id
GROUP BY r.role_id, r.role_title, c.client_name, fs.high_flags, fs.medium_flags;

-- √çndice en la vista materializada
CREATE INDEX idx_mv_pipeline_metrics_role ON mv_pipeline_metrics(role_id);

-- Refrescar vista cada hora o con trigger
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_pipeline_metrics;
```

**Uso desde Python:**
```python
# Query simple y r√°pida
result = await db.execute(
    select(mv_pipeline_metrics).where(mv_pipeline_metrics.c.client_id == client_id)
)
```

---

### Query 3: B√∫squeda de candidatos duplicados optimizada

**Escenario:** Verificar duplicados al crear nuevos candidatos.

**Query actual:**
```python
async def check_duplicates(self, email=None, phone=None, job_opening_id=None):
    query = select(Candidate).where(Candidate.is_duplicate == False)
    
    filters = []
    if email:
        filters.append(Candidate.email_normalized == email.lower().strip())
    if phone:
        filters.append(Candidate.phone_normalized == self._normalize_phone(phone))
    
    if filters:
        query = query.where(or_(*filters))
```

**Optimizaci√≥n con √≠ndice parcial:**
```sql
-- √çndice parcial para candidatos no duplicados
CREATE INDEX idx_candidates_email_not_duplicate 
ON hh_candidates(email_normalized) 
WHERE is_duplicate = false;

CREATE INDEX idx_candidates_phone_not_duplicate 
ON hh_candidates(phone_normalized) 
WHERE is_duplicate = false;

-- Query con EXISTS para mejor performance
SELECT EXISTS (
    SELECT 1 FROM hh_candidates 
    WHERE email_normalized = 'user@example.com' 
    AND is_duplicate = false
) as email_exists,
EXISTS (
    SELECT 1 FROM hh_candidates 
    WHERE phone_normalized = '1234567890'
    AND is_duplicate = false
) as phone_exists;
```

---

## üìã RESUMEN EJECUTIVO

### Seguridad: 6/10 ‚ö†Ô∏è
| Aspecto | Estado | Prioridad |
|---------|--------|-----------|
| Usuarios por servicio | ‚ùå No implementado | CR√çTICO |
| SSL/TLS en tr√°nsito | ‚ùå No configurado | CR√çTICO |
| Cifrado en reposo | ‚ö†Ô∏è No configurado | ALTO |
| Backups autom√°ticos | ‚ùå No implementado | CR√çTICO |
| Auditor√≠a b√°sica | ‚úÖ Implementada | OK |
| Pool de conexiones | ‚úÖ Configurado | OK |

### Performance: 8/10 ‚úÖ
| Aspecto | Estado | Nota |
|---------|--------|------|
| √çndices definidos | ‚úÖ Excelente | Bien cubiertos |
| N+1 Queries | ‚ö†Ô∏è Parcial | Algunos casos detectados |
| Paginaci√≥n | ‚úÖ Implementada | Offset + Cursor |
| Pool de conexiones | ‚úÖ Configurado | Adecuado |
| Migraciones reversibles | ‚úÖ Completas | OK |

### Acciones Prioritarias:
1. **CR√çTICO:** Crear usuarios de BD con permisos m√≠nimos
2. **CR√çTICO:** Configurar SSL/TLS para conexiones
3. **CR√çTICO:** Implementar backups automatizados
4. **ALTO:** Configurar cifrado para datos sensibles (PII)
5. **MEDIO:** Optimizar queries N+1 detectados
6. **MEDIO:** Implementar b√∫squeda full-text para candidatos
